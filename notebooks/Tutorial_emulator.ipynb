{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd4e261-02e6-4dd0-80f3-4decc738c1ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "381390f9-fa9f-4920-aa78-708e7186b14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/astro/scratch/lcabayol/anaconda3/envs/DESIenv6/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# our modules\n",
    "from lace.archive import gadget_archive\n",
    "from lace.archive import nyx_archive\n",
    "from lace.emulator.nn_emulator import NNEmulator\n",
    "from lace.emulator.gp_emulator import GPEmulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fcc325-822b-4fba-a94f-ce8558349aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gadget_emu_params = ['Delta2_p', 'n_p','mF', 'sigT_Mpc', 'gamma', 'kF_Mpc']\n",
    "nyx_emu_params = ['Delta2_p', 'n_p','mF', 'sigT_Mpc', 'gamma', 'lambda_P']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5533bc70-cbd1-4dc6-95c1-9bf897ae6aa4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CREATE TRAINING AND TESTING ARCHIVE (Gadget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5a695e-566d-4d58-8fce-de9122626c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive = gadget_archive.GadgetArchive(postproc=\"Pedersen21\")\n",
    "training_data=archive.get_training_data()\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5527d0a7-239a-46b1-9412-55ff5912a284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data = archive.get_testing_data(sim_label='mpg_central')\n",
    "len(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f653fea-d9a4-40ba-931c-d0cd62ea0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "kMpc = testing_data[0]['k_Mpc']\n",
    "kMpc = kMpc[(kMpc>0) & (kMpc<4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb52bb-1bce-4bc9-80db-8fb8ec83af54",
   "metadata": {
    "tags": []
   },
   "source": [
    "# NEURAL NETWORK EMULATOR  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675bf7ec-04d5-41dd-8ab0-c6536a324877",
   "metadata": {},
   "source": [
    "#### To create an emulator object, we can call NNemulator (to create a neural network emulator) or GP emulator (to create a Gaussian process emulator). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38908cb-f1af-487f-8230-91c637164b7e",
   "metadata": {},
   "source": [
    "### Example 1: We can train a custom emulator... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024a3117-2391-41ab-b4ce-f40ba143e5e9",
   "metadata": {},
   "source": [
    "#### A. passing a custom archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b9b815-32c9-4b86-a4bd-cb325e4204a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use custom archive provided by the user\n",
      "Selected custom emulator\n"
     ]
    }
   ],
   "source": [
    "emulator = NNEmulator(archive=archive, nepochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94442a35-0182-4393-8496-a412f042dc39",
   "metadata": {},
   "source": [
    "### or a training_set label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0b1aa8-0a6d-4fc5-8d31-25bb8754edd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Cabayol23\n",
      "Selected custom emulator\n"
     ]
    }
   ],
   "source": [
    "emulator = NNEmulator(training_set='Cabayol23',nepochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb0fb3b-ebb9-43bd-adf1-dbfe0e2ca91c",
   "metadata": {},
   "source": [
    "#### If none or both are provided, the emulator fails. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888bee3-7d40-40d8-ab0a-ef518506b8e7",
   "metadata": {},
   "source": [
    "### Example 2: We can train a pre defined emulator... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec75ece7-b32c-4f71-8f37-e8822ec39c1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### A. with a training_set label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f904e2-8089-4321-935d-e4405045f419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Cabayol23\n",
      "Select emulator in Cabayol23\n",
      "Neural network emulating the optimal P1D of Gadget simulations fitting coefficients to a 5th degree polynomial. It goes to scales of 4Mpc^{-1} and z<4.5. The parameters passed to the emulator will be overwritten to match these ones\n"
     ]
    }
   ],
   "source": [
    "emulator = NNEmulator(training_set='Cabayol23', emulator_label='Cabayol23', nepochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a078d9f-2863-4114-8203-3a0d1f8188dd",
   "metadata": {},
   "source": [
    "#### B. with an archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7878459-d459-418d-9ba7-52aea2c1e6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use custom archive provided by the user\n",
      "Select emulator in Cabayol23\n",
      "Neural network emulating the optimal P1D of Gadget simulations fitting coefficients to a 5th degree polynomial. It goes to scales of 4Mpc^{-1} and z<4.5. The parameters passed to the emulator will be overwritten to match these ones\n"
     ]
    }
   ],
   "source": [
    "# currently we are passing a Pedersen21 archive and asking for Cabayol23 emulator. Should this crash?\n",
    "emulator = NNEmulator(archive=archive,  emulator_label='Cabayol23', nepochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de9218-3a1c-4be1-a7d4-38522294c059",
   "metadata": {},
   "source": [
    "### Example 3: Load a pre-trained emulator, providing the path of the saved network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "640d6360-0f44-438e-83a4-358a7e20c15f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Cabayol23\n",
      "Select emulator in Cabayol23\n",
      "Neural network emulating the optimal P1D of Gadget simulations fitting coefficients to a 5th degree polynomial. It goes to scales of 4Mpc^{-1} and z<4.5. The parameters passed to the emulator will be overwritten to match these ones\n",
      "Model loaded. No training needed\n"
     ]
    }
   ],
   "source": [
    "# this is now broken (we can not load pre-trained NN models)\n",
    "emulator = NNEmulator(training_set='Cabayol23',emulator_label='Cabayol23',model_path='NNmodels/NNEmulator_LaCEHC.pt', train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1374c31-e75e-4e6e-90b4-4f1552de739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1d = emulator.emulate_p1d_Mpc(testing_data[0],kMpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181a3732-a3cb-4392-93af-4bb036be9356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5319781 , 2.1599364 , 1.9428859 , 1.7684447 , 1.6238589 ,\n",
       "       1.5021849 , 1.3982939 , 1.3083504 , 1.2294911 , 1.159565  ,\n",
       "       1.0969394 , 1.0403605 , 0.9888522 , 0.94164586, 0.89812785,\n",
       "       0.8578039 , 0.82027036, 0.78519607, 0.7523051 , 0.72136647,\n",
       "       0.6921847 , 0.6645939 , 0.63845146, 0.61363417, 0.5900351 ,\n",
       "       0.5675608 , 0.5461285 , 0.52566576, 0.5061074 , 0.48739573,\n",
       "       0.4694784 , 0.45230857, 0.43584356, 0.4200445 , 0.40487593,\n",
       "       0.39030534, 0.37630257, 0.36284018, 0.34989235, 0.33743516,\n",
       "       0.3254463 , 0.3139052 ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6fe68-f1a0-47dd-b745-29373079a046",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GAUSSIAN PROCESS EMULATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbac6c6-4dd3-4bbe-a5e9-ba6a62020032",
   "metadata": {},
   "source": [
    "## The Gaussian process emulator uses the following default parameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace75288-7cce-4400-8c13-c5478342af3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "- paramList=['Delta2_p', 'n_p','mF', 'sigT_Mpc', 'gamma', 'kF_Mpc']\n",
    "- kmax_Mpc=10\n",
    "- ndeg=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d1f0777-2175-4f90-8485-67bbaa1992db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive = gadget_archive.GadgetArchive(postproc=\"Pedersen21\")\n",
    "training_data=archive.get_training_data()\n",
    "len(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4567cffd-be0b-468c-9cc3-d5354c091e98",
   "metadata": {},
   "source": [
    "### Example 1: Train custom emulator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08cae5-52ad-4ff0-bd8b-8cd424c7e3b8",
   "metadata": {},
   "source": [
    "#### with a defined training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80ca12bd-fef6-4d39-b9f4-2bd00c61ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Pedersen21\n",
      "Selected custom emulator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /data/astro/scratch/lcabayol/anaconda3/envs/DESIenv6/lib/python3.10/site-packages/paramz/parameterized.py:61: RuntimeWarning:Don't forget to initialize by self.initialize_parameter()!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GP on 330 points\n",
      "GPs optimised in 0.48 seconds\n"
     ]
    }
   ],
   "source": [
    "emulator = GPEmulator(training_set='Pedersen21')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6fd00-e644-4722-a478-64f21846ae66",
   "metadata": {},
   "source": [
    "#### with a custom archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b79b0b-a691-4e83-ac6c-4b6479949dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use custom archive provided by the user\n",
      "Selected custom emulator\n",
      "Training GP on 330 points\n",
      "GPs optimised in 0.47 seconds\n"
     ]
    }
   ],
   "source": [
    "emulator = GPEmulator(archive=archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2c02e-fd38-4ab2-9e18-b4175b9821e4",
   "metadata": {},
   "source": [
    "#### if both are provided, the emulator fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c0df38-c714-435f-8681-b24f8f030744",
   "metadata": {},
   "source": [
    "### Example 2: Pre-defined GP emulators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cefcea6b-9f9b-4898-9b39-740bde8a6770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Pedersen21\n",
      "Select emulator in Pedersen21\n",
      "Gaussian Process emulator predicting the P1D at each k-bin. It goes to scales of 3Mpc^{-1} and z<4.5. The parameters passed to the emulator will be overwritten to match these ones.\n",
      "Training GP on 330 points\n",
      "GPs optimised in 0.97 seconds\n"
     ]
    }
   ],
   "source": [
    "emulator = GPEmulator(training_set='Pedersen21', emulator_label='Pedersen21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdcfafb1-454c-4806-90e9-25634ee03858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Pedersen21\n",
      "Select emulator in Pedersen23\n",
      "Gaussian Process emulator predicting the optimal P1Dfitting coefficients to a 5th degree polynomial. It goes to scales of 4Mpc^{-1} and z<4.5. The parameters passed to the emulator will be overwritten to match these ones\n",
      "Training GP on 330 points\n",
      "GPs optimised in 0.47 seconds\n"
     ]
    }
   ],
   "source": [
    "emulator = GPEmulator(training_set='Pedersen21', emulator_label='Pedersen23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e658e0-028f-4923-8ee5-679915f921b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1d = emulator.emulate_p1d_Mpc(testing_data[0],kMpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80384581-708d-414e-9cda-8b09e7d15cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Pedersen21\n",
      "Selected custom emulator\n",
      "Training GP on 330 points\n",
      "GPs optimised in 0.48 seconds\n"
     ]
    }
   ],
   "source": [
    "emulator = GPEmulator(training_set='Pedersen21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90012e78-5a37-4a78-a95d-48d7a0b3ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1d = emulator.emulate_p1d_Mpc(testing_data[0],kMpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc52d34",
   "metadata": {},
   "source": [
    "## LaCE-Nyx emulator (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bef979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyx_fname = '/data/desi/scratch/HydroData/Emulator/nyx_files/models.hdf5'\n",
    "archive = nyx_archive.NyxArchive(nyx_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d1e2a0-0634-4fc3-86a2-1d711162deb5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, dataset, TensorDataset\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# LaCE modules\n",
    "from lace.archive import gadget_archive\n",
    "from lace.archive import nyx_archive\n",
    "from lace.cosmo import camb_cosmo\n",
    "from lace.cosmo import fit_linP\n",
    "from lace.emulator import poly_p1d\n",
    "from lace.emulator import utils\n",
    "from lace.emulator import nn_architecture\n",
    "from lace.emulator import base_emulator\n",
    "\n",
    "cosmo_fid = camb_cosmo.get_cosmology()\n",
    "import copy\n",
    "\n",
    "\n",
    "class NNEmulator(base_emulator.BaseEmulator):\n",
    "    \"\"\"A class for training an emulator.\n",
    "\n",
    "    Args:\n",
    "        archive (class): Data archive used for training the emulator.\n",
    "            Required when using a custom emulator.\n",
    "        training_set: Specific training set.  Options are\n",
    "            'Cabayol23'.\n",
    "        emu_params (lsit): A list of emulator parameters.\n",
    "        emulator_label (str): Specific emulator label. Options are\n",
    "            'Cabayol23' and 'Cabayol23_Nyx'.\n",
    "        kmax_Mpc (float): The maximum k in Mpc^-1 to use for training. Default is 3.5.\n",
    "        nepochs (int): The number of epochs to train for. Default is 200.\n",
    "        model_path (str): The path to a pretrained model. Default is None.\n",
    "        train (bool): Wheather to train the emulator or not. Default True. If False, a model path must is required.\n",
    "        initial_weights (bool): Wheather to initialize the network always with a set of pre-defined random weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        archive=None,\n",
    "        training_set=None,\n",
    "        emu_params=['Delta2_p', 'n_p','mF', 'sigT_Mpc', 'gamma', 'kF_Mpc'], \n",
    "        emulator_label=None,\n",
    "        kmax_Mpc=4,\n",
    "        ndeg=5,\n",
    "        nepochs=100,\n",
    "        step_size=75,\n",
    "        train=True,\n",
    "        initial_weights=True,\n",
    "        save_path=None,\n",
    "        model_path=None,\n",
    "    ):\n",
    "        self.emu_params = emu_params\n",
    "        self.kmax_Mpc = kmax_Mpc\n",
    "        self.nepochs = nepochs\n",
    "        self.step_size = step_size\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        self.ndeg = ndeg\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.save_path = save_path\n",
    "        self.lace_path = os.environ[\"LACE_REPO\"] + \"/\"\n",
    "        self.models_dir = os.path.join(self.lace_path, \"lace/emulator/\")\n",
    "        \n",
    "        #temporary hack:\n",
    "\n",
    "        # check input #\n",
    "        training_set_all = [\"Pedersen21\", \"Cabayol23\", \"Nyx23\"]\n",
    "        if (archive!=None)&(training_set!=None):\n",
    "            raise ValueError(\"Conflict! Both custom archive and training_set provided\")\n",
    "        \n",
    "        if training_set is not None:\n",
    "            try:\n",
    "                if training_set in training_set_all:\n",
    "                    print(f\"Selected training set from {training_set}\")\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\n",
    "                        \"Invalid training_set value. Available options: \",\n",
    "                        training_set_all,\n",
    "                    )\n",
    "                    raise\n",
    "            except:\n",
    "                print(\"An error occurred while checking the training_set value.\")\n",
    "                raise\n",
    "                \n",
    "            # read Gadget archive with the right postprocessing\n",
    "            \n",
    "            #self.archive=gadget_archive.GadgetArchive(postproc=training_set)\n",
    "            #self.training_data = self.archive.get_training_data()\n",
    "            \n",
    "                    \n",
    "        elif archive!=None and training_set==None:\n",
    "            print(\"Use custom archive provided by the user\")\n",
    "            self.archive = archive\n",
    "            self.training_data = archive.get_training_data()\n",
    "\n",
    "        elif (archive==None)&(training_set==None):\n",
    "            raise(ValueError('Archive or training_set must be provided'))\n",
    "            \n",
    "        if training_set in ['Pedersen21','Cabayol23']:\n",
    "            self.archive=gadget_archive.GadgetArchive(postproc=training_set)\n",
    "            self.training_data = self.archive.get_training_data()\n",
    "            \n",
    "        elif training_set in ['Nyx23']:\n",
    "            self.archive = nyx_archive.NyxArchive(file_name=nyx_fname)\n",
    "            self.training_data = archive.get_training_data()\n",
    "            \n",
    "            \n",
    "        emulator_label_all = [\"Cabayol23\", \"Cabayol23_Nyx\"]\n",
    "        if emulator_label is not None:  \n",
    "            try:\n",
    "                if emulator_label in emulator_label_all:\n",
    "                    print(f\"Select emulator in {emulator_label}\")\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\n",
    "                        \"Invalid emulator_label value. Available options: \",\n",
    "                        emulator_label_all,\n",
    "                    )\n",
    "                    raise\n",
    "\n",
    "            except:\n",
    "                print(\"An error occurred while checking the emulator_label value.\")\n",
    "                raise\n",
    "\n",
    "            if emulator_label == \"Cabayol23\":\n",
    "                \n",
    "                print(\n",
    "                    r\"Neural network emulating the optimal P1D of Gadget simulations \"\n",
    "                    + \"fitting coefficients to a 5th degree polynomial. It \"\n",
    "                    + \"goes to scales of 4Mpc^{-1} and z<4.5. The parameters \"\n",
    "                    + \"passed to the emulator will be overwritten to match \"\n",
    "                    + \"these ones\"\n",
    "                )\n",
    "                self.emu_params = [\"Delta2_p\", \"n_p\", \"mF\", \"sigT_Mpc\", \"gamma\", \"kF_Mpc\"]\n",
    "                self.kmax_Mpc, self.ndeg, self.nepochs,self.step_size = 4, 5, 100, 75\n",
    "                \n",
    "            if emulator_label == \"Cabayol23_Nyx\":\n",
    "                \n",
    "                print(\n",
    "                    r\"Neural network emulating the optimal P1D of Nyx simulations \"\n",
    "                    + \"fitting coefficients to a 5th degree polynomial. It \"\n",
    "                    + \"goes to scales of 4Mpc^{-1} and z<4.5. The parameters \"\n",
    "                    + \"passed to the emulator will be overwritten to match \"\n",
    "                    + \"these ones\"\n",
    "                )\n",
    "                \n",
    "\n",
    "                self.emu_params = [\"Delta2_p\", \"n_p\", \"mF\", \"sigT_Mpc\", \"gamma\", \"lambda_P\"]\n",
    "                self.kmax_Mpc, self.ndeg, self.nepochs, self.step_size = 4, 5, 1000, 750\n",
    "                                \n",
    "                \n",
    "        else:\n",
    "            print(\"Selected custom emulator\")            \n",
    "            \n",
    "        if train == False: \n",
    "            if (emulator_label==None)|(training_set==None):\n",
    "                raise ValueError(\"Pre-trained models can only be loaded passing an emulator_label and a training_set\")\n",
    "\n",
    "            if self.model_path == None:\n",
    "                raise ValueError(\"If train==False, model path is required.\")\n",
    "\n",
    "            else:\n",
    "                pretrained_weights = torch.load(\n",
    "                    os.path.join(self.models_dir, self.model_path), map_location=\"cpu\"\n",
    "                )\n",
    "                self.nn = nn_architecture.MDNemulator_polyfit(\n",
    "                    nhidden=5, ndeg=self.ndeg\n",
    "                )\n",
    "                self.nn.load_state_dict(pretrained_weights['model'])\n",
    "                self.nn.to(self.device)\n",
    "                print(\"Model loaded. No training needed\")\n",
    "                \n",
    "                emulator_settings = pretrained_weights['emulator_params']\n",
    "                \n",
    "                training_set_loaded = emulator_settings['training_set']\n",
    "                emulator_label_loaded = emulator_settings['emulator_label']        \n",
    "                drop_sim_loaded = emulator_settings['drop_sim']   \n",
    "                \n",
    "                if (emulator_label_loaded!=emulator_label)|(training_set_loaded!=training_set):\n",
    "                    raise ValueError(f\"This model correspond to an emulator_label {emulator_label} and \"+\n",
    "                                     f\"a training set {training_set_loaded} and does not match the passed arguments\"\n",
    "                                    )\n",
    "                    \n",
    "                if emulator_settings['drop_sim'] != None:\n",
    "                    dropsim=emulator_params['drop_sim']\n",
    "                    print(f'WARNING: Model trained without simulation set {dropsim}') \n",
    "                    \n",
    "                \n",
    "            if training_set=='Cabayol23':\n",
    "                \n",
    "                kMpc_train = self._obtain_sim_params()\n",
    "                log_kMpc_train = torch.log10(kMpc_train).to(self.device)\n",
    "                self.log_kMpc = log_kMpc_train\n",
    "                \n",
    "            elif training_set=='Nyx':\n",
    "                raise ValueError(\"Work in progress\")\n",
    "                \n",
    "        else:           \n",
    "                                        \n",
    "            self.initial_weights = initial_weights\n",
    "            if self.initial_weights == True:\n",
    "                # loads set of pre-defined random weights\n",
    "                if self.kmax_Mpc == 4:\n",
    "                    self.initial_weights_path = os.path.join(\n",
    "                        self.models_dir, \"initial_params/initial_weights.pt\"\n",
    "                    )\n",
    "                if self.kmax_Mpc == 8:\n",
    "                    self.initial_weights_path = os.path.join(\n",
    "                        self.models_dir, \"initial_params/initial_weights_extended.pt\"\n",
    "                    )\n",
    "\n",
    "\n",
    "            self.train()\n",
    "\n",
    "            if self.save_path != None:\n",
    "                # saves the model in the predefined path after training\n",
    "                self.save_emulator()\n",
    "\n",
    "    def _sort_dict(self, dct, keys):\n",
    "        \"\"\"\n",
    "        Sort a list of dictionaries based on specified keys.\n",
    "\n",
    "        Args:\n",
    "            dct (list): List of dictionaries to be sorted.\n",
    "            keys (list): List of keys to sort the dictionaries by.\n",
    "\n",
    "        Returns:\n",
    "            list: The sorted list of dictionaries.\n",
    "        \"\"\"\n",
    "        for d in dct:\n",
    "            sorted_d = {\n",
    "                k: d[k] for k in keys\n",
    "            }  # create a new dictionary with only the specified keys\n",
    "            d.clear()  # remove all items from the original dictionary\n",
    "            d.update(\n",
    "                sorted_d\n",
    "            )  # update the original dictionary with the sorted dictionary\n",
    "        return dct\n",
    "\n",
    "    def _obtain_sim_params(self):\n",
    "        \"\"\"\n",
    "        Obtain simulation parameters.\n",
    "\n",
    "        Returns:\n",
    "            k_Mpc (np.ndarray): Simulation k values.\n",
    "            Nz (int): Number of redshift values.\n",
    "            Nk (int): Number of k values.\n",
    "            k_Mpc_train (tensor): k values in the k training range\n",
    "        \"\"\"\n",
    "\n",
    "        # AFR: not sure exactly what we are doing here. \n",
    "        # It looks like some code to set self.k_Mpc and self.Nz\n",
    "        sim_0 = copy.deepcopy(self.archive)\n",
    "        sim_0_training_data = sim_0.get_training_data()\n",
    "        sim_0_training_data = [d for d in sim_0_training_data if d[\"sim_label\"] == \"mpg_0\"]\n",
    "        sim_zs = [data[\"z\"] for data in sim_0_training_data]\n",
    "        Nz = len(sim_zs)\n",
    "        k_Mpc = sim_0.data[0][\"k_Mpc\"]\n",
    "        self.k_Mpc = k_Mpc\n",
    "\n",
    "        k_mask = (k_Mpc < self.kmax_Mpc) & (k_Mpc > 0)\n",
    "        k_Mpc_train = k_Mpc[k_mask]\n",
    "        Nk = len(k_Mpc_train)\n",
    "        k_Mpc_train = torch.Tensor(k_Mpc_train)\n",
    "\n",
    "        self.Nz = Nz\n",
    "        self.Nk = Nk\n",
    "        \n",
    "\n",
    "        data = [\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in self.training_data[i].items()\n",
    "                if key in self.emu_params\n",
    "            }\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        data = self._sort_dict(\n",
    "            data, self.emu_params\n",
    "        )  # sort the data by emulator parameters\n",
    "        data = [list(data[i].values()) for i in range(len(self.training_data))]\n",
    "        data = np.array(data)\n",
    "\n",
    "        paramlims = np.concatenate(\n",
    "            (\n",
    "                data.min(0).reshape(len(data.min(0)), 1),\n",
    "                data.max(0).reshape(len(data.max(0)), 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "        self.paramLims = paramlims\n",
    "\n",
    "        training_label = [\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in self.training_data[i].items()\n",
    "                if key in [\"p1d_Mpc\"]\n",
    "            }\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        training_label = [\n",
    "            list(training_label[i].values())[0][1 : (self.Nk + 1)].tolist()\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        training_label = np.array(training_label)\n",
    "        self.yscalings = np.median(training_label)\n",
    "\n",
    "        return k_Mpc_train\n",
    "\n",
    "    def _get_training_data_nn(self):\n",
    "        \"\"\"\n",
    "        Given an archive and key_av, it obtains the training data based on self.emu_params\n",
    "        Sorts the training data according to self.emu_params and scales the data based on self.paramLims\n",
    "        Finally, it returns the training data as a torch.Tensor object.\n",
    "        \"\"\"\n",
    "        training_data = [\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in self.training_data[i].items()\n",
    "                if key in self.emu_params\n",
    "            }\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        training_data = self._sort_dict(training_data, self.emu_params)\n",
    "        training_data = [\n",
    "            list(training_data[i].values())\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "\n",
    "        training_data = np.array(training_data)\n",
    "        training_data = (training_data - self.paramLims[:, 0]) / (\n",
    "            self.paramLims[:, 1] - self.paramLims[:, 0]\n",
    "        ) - 0.5\n",
    "        training_data = torch.Tensor(training_data)\n",
    "\n",
    "        return training_data\n",
    "\n",
    "    def _get_training_pd1_nn(self):\n",
    "        \"\"\"\n",
    "        Method to get the p1d_Mpc values from the training data in a format that the NN emulator can ingest\n",
    "        It gets the P!D from the archive and scales it.\n",
    "        Finally, it returns the scaled values as a torch.Tensor object along with the scaling factor.\n",
    "        \"\"\"\n",
    "        training_label = [\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in self.training_data[i].items()\n",
    "                if key in [\"p1d_Mpc\"]\n",
    "            }\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        training_label = [\n",
    "            list(training_label[i].values())[0][1 : (self.Nk + 1)].tolist()\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "\n",
    "        training_label = np.array(training_label)\n",
    "        # yscalings = np.median(training_label)\n",
    "        training_label = np.log10(training_label / self.yscalings)\n",
    "        training_label = torch.Tensor(training_label)\n",
    "\n",
    "        # self.yscalings=yscalings\n",
    "\n",
    "        return training_label  # , yscalings\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Trains the emulator with given key_list using the archive data.\n",
    "        Args:\n",
    "        key_list (list): List of keys to be used for training\n",
    "\n",
    "        Returns:None\n",
    "        \"\"\"\n",
    "\n",
    "        kMpc_train = self._obtain_sim_params()\n",
    "\n",
    "        log_kMpc_train = torch.log10(kMpc_train).to(self.device)\n",
    "\n",
    "        self.log_kMpc = log_kMpc_train\n",
    "\n",
    "        self.nn = nn_architecture.MDNemulator_polyfit(nhidden=5, ndeg=self.ndeg)\n",
    "        if self.initial_weights == True:\n",
    "            initial_weights_params = torch.load(self.initial_weights_path, map_location=\"cpu\")\n",
    "            self.nn.load_state_dict(initial_weights_params)\n",
    "\n",
    "        optimizer = optim.Adam(\n",
    "            self.nn.parameters(), lr=1e-3, weight_decay=1e-4\n",
    "        )  #\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, self.step_size, gamma=0.1)\n",
    "\n",
    "        training_data = self._get_training_data_nn()\n",
    "        training_label = self._get_training_pd1_nn()\n",
    "\n",
    "\n",
    "        trainig_dataset = TensorDataset(training_data, training_label)\n",
    "        loader_train = DataLoader(trainig_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "        self.nn.to(self.device)\n",
    "\n",
    "        t0 = time.time()\n",
    "        for epoch in range(self.nepochs):\n",
    "            for datain, p1D_true in loader_train:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                coeffsPred, coeffs_logerr = self.nn(datain.to(self.device))  #\n",
    "                coeffs_logerr = torch.clamp(coeffs_logerr, -10, 5)\n",
    "                coeffserr = torch.exp(coeffs_logerr) ** 2\n",
    "\n",
    "                powers = torch.arange(0, self.ndeg + 1, 1).to(self.device)\n",
    "                P1Dpred = torch.sum(\n",
    "                    coeffsPred[:, powers, None]\n",
    "                    * (self.log_kMpc[None, :] ** powers[None, :, None]),\n",
    "                    axis=1,\n",
    "                )\n",
    "\n",
    "                powers_err = torch.arange(0, self.ndeg * 2 + 1, 2).to(self.device)\n",
    "                P1Derr = torch.sqrt(\n",
    "                    torch.sum(\n",
    "                        coeffserr[:, powers, None]\n",
    "                        * (self.log_kMpc[None, :] ** powers_err[None, :, None]),\n",
    "                        axis=1,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                P1Dlogerr = torch.log(P1Derr)\n",
    "\n",
    "                log_prob = ((P1Dpred - p1D_true.to(self.device)) / P1Derr).pow(\n",
    "                    2\n",
    "                ) + 2 * P1Dlogerr  #\n",
    "\n",
    "                loss = torch.nansum(log_prob, 1)\n",
    "                loss = torch.nanmean(loss, 0)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "    def save_emulator(self):\n",
    "        torch.save(self.nn.state_dict(), self.save_path)\n",
    "\n",
    "        \n",
    "    def emulate_p1d_Mpc(self, model, k_Mpc, return_covar=False, z=None):\n",
    "        k_Mpc = torch.Tensor(k_Mpc)\n",
    "        log_kMpc = torch.log10(k_Mpc).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            emu_call = {}\n",
    "            for param in self.emu_params:\n",
    "                emu_call[param] = model[param]\n",
    "\n",
    "            emu_call = {k: emu_call[k] for k in self.emu_params}\n",
    "            emu_call = list(emu_call.values())\n",
    "            emu_call = np.array(emu_call)\n",
    "\n",
    "            emu_call = (emu_call - self.paramLims[:, 0]) / (\n",
    "                self.paramLims[:, 1] - self.paramLims[:, 0]\n",
    "            ) - 0.5\n",
    "            emu_call = torch.Tensor(emu_call).unsqueeze(0)\n",
    "\n",
    "            # ask emulator to emulate P1D (and its uncertainty)\n",
    "            coeffsPred, coeffs_logerr = self.nn(emu_call.to(self.device))\n",
    "            coeffs_logerr = torch.clamp(coeffs_logerr, -10, 5)\n",
    "            coeffserr = torch.exp(coeffs_logerr) ** 2\n",
    "\n",
    "            powers = torch.arange(0, self.ndeg + 1, 1).to(self.device)\n",
    "            emu_p1d = torch.sum(\n",
    "                coeffsPred[:, powers, None]\n",
    "                * (log_kMpc[None, :] ** powers[None, :, None]),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            powers_err = torch.arange(0, self.ndeg * 2 + 1, 2).to(self.device)\n",
    "            emu_p1derr = torch.sqrt(\n",
    "                torch.sum(\n",
    "                    coeffserr[:, powers, None]\n",
    "                    * (log_kMpc[None, :] ** powers_err[None, :, None]),\n",
    "                    axis=1,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            emu_p1d = emu_p1d.detach().cpu().numpy().flatten()\n",
    "            emu_p1derr = emu_p1derr.detach().cpu().numpy().flatten()\n",
    "\n",
    "            emu_p1derr = 10 ** (emu_p1d) * np.log(10) * emu_p1derr * self.yscalings\n",
    "            emu_p1d = 10 ** (emu_p1d) * self.yscalings\n",
    "\n",
    "        if return_covar==True:\n",
    "            covar = np.outer(emu_p1derr, emu_p1derr)\n",
    "            return emu_p1d, covar\n",
    "        \n",
    "        else:\n",
    "            return emu_p1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caee4231-d422-4776-8e92-0d2a204f2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = archive.get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d7668bd-ccb4-4bf8-9a93-46fc7d3df94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        key: value\n",
    "        for key, value in training_data[i].items()\n",
    "        if key in nyx_emu_params\n",
    "    }\n",
    "    for i in range(len(training_data))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84e27230-7a31-4c50-b2e9-8b89a257f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [list(data[i].values()) for i in range(len(training_data))]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b624ba83-8679-4e0b-890c-221ed50e2345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664c4450-1394-4638-8efd-0deda49a908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.68674392e-02,  7.84609292e-01],\n",
       "       [-2.40832397e+00, -2.18690511e+00],\n",
       "       [ 1.78113330e-02,  9.72814387e-01],\n",
       "       [            nan,             nan],\n",
       "       [            nan,             nan],\n",
       "       [ 5.07443755e+01,  9.10152900e+01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramlims = np.concatenate(\n",
    "    (\n",
    "        data.min(0).reshape(len(data.min(0)), 1),\n",
    "        data.max(0).reshape(len(data.max(0)), 1),\n",
    "    ),\n",
    "    1,\n",
    ")\n",
    "paramlims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5fa2656-cee4-4a22-b477-4bab8953dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kMpc = training_data[0]['k_Mpc']\n",
    "kMpc = kMpc[(kMpc>0) & (kMpc<4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e90f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use custom archive provided by the user\n",
      "Selected custom emulator\n"
     ]
    }
   ],
   "source": [
    "emulator = NNEmulator(archive=archive, nepochs=1,\n",
    "                      emu_params=['Delta2_p', 'n_p','mF', 'sigT_Mpc','gamma','lambda_P' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1c59e3-9b21-4bf6-859a-bd525a73ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected training set from Nyx23\n",
      "Selected custom emulator\n"
     ]
    }
   ],
   "source": [
    "emulator = NNEmulator(training_set='Nyx23', nepochs=1,\n",
    "                      emu_params=['Delta2_p', 'n_p','mF', 'sigT_Mpc','gamma','lambda_P' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d084d14-d72b-4a25-ac2c-3ca207242500",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use custom archive provided by the user\n",
      "Select emulator in Cabayol23_Nyx\n",
      "Neural network emulating the optimal P1D of Nyx simulations fitting coefficients to a 5th degree polynomial. It goes to scales of 4Mpc^{-1} and z<4.5. The parameters passed to the emulator will be overwritten to match these ones\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m emulator \u001b[38;5;241m=\u001b[39m \u001b[43mNNEmulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43marchive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marchive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memulator_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCabayol23_Nyx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/astro/scratch/lcabayol/anaconda3/envs/DESIenv6/lib/python3.10/site-packages/lace-1.0.1-py3.10.egg/lace/emulator/nn_emulator.py:228\u001b[0m, in \u001b[0;36mNNEmulator.__init__\u001b[0;34m(self, archive, training_set, emu_params, emulator_label, kmax_Mpc, ndeg, nepochs, step_size, train, initial_weights, save_path, model_path)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmax_Mpc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m8\u001b[39m:\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_weights_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minitial_params/initial_weights_extended.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# saves the model in the predefined path after training\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_emulator()\n",
      "File \u001b[0;32m/data/astro/scratch/lcabayol/anaconda3/envs/DESIenv6/lib/python3.10/site-packages/lace-1.0.1-py3.10.egg/lace/emulator/nn_emulator.py:450\u001b[0m, in \u001b[0;36mNNEmulator.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    447\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnansum(log_prob, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    448\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnanmean(loss, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 450\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    453\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/data/astro/scratch/lcabayol/anaconda3/envs/DESIenv6/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/astro/scratch/lcabayol/anaconda3/envs/DESIenv6/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emulator = NNEmulator(archive=archive, emulator_label='Cabayol23_Nyx', nepochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b744f0d-bf82-4723-a516-d5969e3666db",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1d = emulator.emulate_p1d_Mpc(training_data[0],kMpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dbc320b-e3bf-4834-9ec9-327d70678f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.68674392e-02,  7.84609292e-01],\n",
       "       [-2.40832397e+00, -2.18690511e+00],\n",
       "       [ 1.78113330e-02,  9.72814387e-01],\n",
       "       [            nan,             nan],\n",
       "       [            nan,             nan],\n",
       "       [ 5.07443755e+01,  9.10152900e+01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emulator.paramLims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _obtain_sim_params(self):\n",
    "        \"\"\"\n",
    "        Obtain simulation parameters.\n",
    "\n",
    "        Returns:\n",
    "            k_Mpc (np.ndarray): Simulation k values.\n",
    "            Nz (int): Number of redshift values.\n",
    "            Nk (int): Number of k values.\n",
    "            k_Mpc_train (tensor): k values in the k training range\n",
    "        \"\"\"\n",
    "\n",
    "        # AFR: not sure exactly what we are doing here. \n",
    "        # It looks like some code to set self.k_Mpc and self.Nz\n",
    "        sim_0 = copy.deepcopy(self.archive)\n",
    "        sim_0_training_data = sim_0.get_training_data()\n",
    "        sim_0_training_data = [d for d in sim_0_training_data if d[\"sim_label\"] == \"mpg_0\"]\n",
    "        sim_zs = [data[\"z\"] for data in sim_0_training_data]\n",
    "        Nz = len(sim_zs)\n",
    "        k_Mpc = sim_0.data[0][\"k_Mpc\"]\n",
    "        self.k_Mpc = k_Mpc\n",
    "\n",
    "        k_mask = (k_Mpc < self.kmax_Mpc) & (k_Mpc > 0)\n",
    "        k_Mpc_train = k_Mpc[k_mask]\n",
    "        Nk = len(k_Mpc_train)\n",
    "        k_Mpc_train = torch.Tensor(k_Mpc_train)\n",
    "\n",
    "        self.Nz = Nz\n",
    "        self.Nk = Nk\n",
    "\n",
    "        data = [\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in self.training_data[i].items()\n",
    "                if key in self.emu_params\n",
    "            }\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        data = self._sort_dict(\n",
    "            data, self.emu_params\n",
    "        )  # sort the data by emulator parameters\n",
    "        data = [list(data[i].values()) for i in range(len(self.training_data))]\n",
    "        data = np.array(data)\n",
    "\n",
    "        paramlims = np.concatenate(\n",
    "            (\n",
    "                data.min(0).reshape(len(data.min(0)), 1),\n",
    "                data.max(0).reshape(len(data.max(0)), 1),\n",
    "            ),\n",
    "            1,\n",
    "        )\n",
    "        self.paramLims = paramlims\n",
    "\n",
    "        training_label = [\n",
    "            {\n",
    "                key: value\n",
    "                for key, value in self.training_data[i].items()\n",
    "                if key in [\"p1d_Mpc\"]\n",
    "            }\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        training_label = [\n",
    "            list(training_label[i].values())[0][1 : (self.Nk + 1)].tolist()\n",
    "            for i in range(len(self.training_data))\n",
    "        ]\n",
    "        training_label = np.array(training_label)\n",
    "        self.yscalings = np.median(training_label)\n",
    "\n",
    "        return k_Mpc_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESIenv6",
   "language": "python",
   "name": "desienv6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
